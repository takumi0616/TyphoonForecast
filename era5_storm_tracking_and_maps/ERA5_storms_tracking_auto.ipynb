{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Tracking automatique de tempêtes dans les réanalyses ERA5\n",
    "\n",
    "Calepin à utiliser pour le calcul de trajectoires de tempêtes remarquables à partir de réanalyses ERA5 de Pmer (fichier msl.nc à récupérer sur Copernicus et à mettre dans le dossier \"data/storm\") :\n",
    "https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels?tab=form\n",
    "\n",
    "Les fichiers texte des trajectoires des tempêtes sont stockés dans le répertoire \"txt\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import xarray as xr\n",
    "import netCDF4\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from cartopy import config\n",
    "from cartopy.util import add_cyclic_point\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.geoaxes import GeoAxes\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "import matplotlib.path as mpath\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.ndimage import maximum_filter, minimum_filter\n",
    "\n",
    "from shapely.geometry import Point\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fonctions de calcul des min/max et conversion longitudes 0 - 360 en -180 - 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_maxmin_points(data, extrema, nsize, symbol, color='k',\n",
    "                       plotValue=True, transform=None):\n",
    "\n",
    "    if (extrema == 'max'):\n",
    "        data_ext = maximum_filter(data, nsize, mode='nearest')\n",
    "    elif (extrema == 'min'):\n",
    "        data_ext = minimum_filter(data, nsize, mode='nearest')\n",
    "    else:\n",
    "        raise ValueError('Value for hilo must be either max or min')\n",
    "\n",
    "    mxy, mxx = np.where(data_ext == data)\n",
    "\n",
    "    for i in range(len(mxy)):\n",
    "        ax.text(data.longitude[mxx[i]].values, data.latitude[mxy[i]].values, symbol, color=color, size=12,\n",
    "                clip_on=True, horizontalalignment='center', verticalalignment='center',\n",
    "                transform=transform)\n",
    "        ax.text(data.longitude[mxx[i]].values, data.latitude[mxy[i]].values,\n",
    "                '\\n' + str(int(data[mxy[i], mxx[i]])),\n",
    "                color=color, size=10, clip_on=True, fontweight='bold',\n",
    "                horizontalalignment='center', verticalalignment='top', transform=transform)\n",
    "\n",
    "def print_maxmin_points(data, extrema, nsize):\n",
    "    if (extrema == 'max'):\n",
    "        data_ext = maximum_filter(data, nsize, mode='nearest')\n",
    "    elif (extrema == 'min'):\n",
    "        data_ext = minimum_filter(data, nsize, mode='nearest')\n",
    "    else:\n",
    "        raise ValueError('Value for hilo must be either max or min')\n",
    "\n",
    "    mxy, mxx = np.where(data_ext == data)\n",
    "\n",
    "    for i in range(len(mxy)):\n",
    "        # Print date lon lat and pressure of the minimum\n",
    "        print(date, data.longitude[mxx[i]].values, data.latitude[mxy[i]].values, int(data[mxy[i], mxx[i]]))\n",
    "\n",
    "def lonflip(da):\n",
    "    lon_name = 'longitude'\n",
    "    da['_longitude_adjusted'] = xr.where(\n",
    "        da[lon_name] > 180,\n",
    "        da[lon_name] - 360,\n",
    "        da[lon_name])\n",
    "    da = (\n",
    "        da\n",
    "        .swap_dims({lon_name: '_longitude_adjusted'})\n",
    "        .sel(**{'_longitude_adjusted': sorted(da._longitude_adjusted)})\n",
    "        .drop(lon_name))\n",
    "    da = da.rename({'_longitude_adjusted': lon_name})\n",
    "    return da"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fonctions pour les graphiques/animations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_boundary_path(lon,lat):\n",
    "    lons,lats=np.meshgrid(lon,lat)\n",
    "    boundary_path = np.array([lons[-1,:],lats[-1,:]])\n",
    "    boundary_path = np.append(boundary_path,np.array([lons[::-1,-1],lats[::-1,-1]]),axis=1)\n",
    "    boundary_path = np.append(boundary_path,np.array([lons[1,::-1],lats[1,::-1]]),axis=1)\n",
    "    boundary_path = np.append(boundary_path,np.array([lons[:,1],lats[:,1]]),axis=1)\n",
    "    boundary_path = mpath.Path(np.swapaxes(boundary_path, 0, 1))\n",
    "    return boundary_path\n",
    "\n",
    "def make_animation(gif_filepath):\n",
    "    from PIL import Image\n",
    "    import os\n",
    "    from IPython.display import Image as IPImage\n",
    "    from IPython.display import display\n",
    "    import time\n",
    "    \n",
    "    image_folder = './anim/'+storm+'/' # répertoire contenant les fichiers PNG\n",
    "    output_file = gif_filepath # nom du fichier de sortie\n",
    "    animation_speed = 0.9 # vitesse de l'animation en secondes\n",
    "    \n",
    "    # Liste tous les fichiers PNG dans le répertoire image_folder\n",
    "    files = sorted(os.listdir(image_folder))\n",
    "    image_files = [f for f in files if f.endswith('.png')]\n",
    "    \n",
    "    # Ouvre chaque fichier PNG et ajoute l'image à une liste\n",
    "    images = []\n",
    "    for filename in image_files:\n",
    "        img = Image.open(os.path.join(image_folder, filename))\n",
    "        images.append(img)\n",
    "    \n",
    "    # Crée l'animation GIF\n",
    "    images[0].save(output_file, save_all=True, append_images=images[1:], duration=int(animation_speed*1000), loop=0)\n",
    "    # Affiche l'animation GIF dans Jupyter\n",
    "    with open(output_file,'rb') as f:\n",
    "        display(IPImage(data=f.read(), format='png'))\n",
    "    # Efface les fichiers PNG\n",
    "    for filename in image_files:\n",
    "        os.remove(image_folder+filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<p><b>Réaliser le tracking automatique pour l'ensemble des tempêtes ci-dessous (à l'exception d'Ophélia, Zorbas et Lorenzo) afin de créer les fichiers texte de toutes les trajectoires.</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Choix de la tempête."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_menu():\n",
    "    print ('1 -- Tempête de Novembre 1982' )\n",
    "    print (\"2 -- 'Ourangan' d'octobre 1987\")\n",
    "    print ('3 -- Herta - Février 1990' )\n",
    "    print ('4 -- Viviane - Février 1990' )\n",
    "    print ('5 -- Braer - Janvier 1993' )\n",
    "    print ('6 -- Lothar - Décembre 1999' )\n",
    "    print ('7 -- Martin - Décembre 1999' )\n",
    "    print ('8 -- Klaus - Janvier 2009' )\n",
    "    print ('9 -- Xynthia - Février 2010' )\n",
    "    print ('10 -- Joachim - Décembre 2011' )\n",
    "    print ('11 -- Zeus - Mars 2017' )\n",
    "    print ('12 -- Ophelia - Octobre 2017 (transition extra tropicale)' )\n",
    "    print ('13 -- Eleanor - Janvier 2018' )\n",
    "    print ('14 -- Zorbas - Septembre 2018 (medicane)')\n",
    "    print ('15 -- Lorenzo - Octobre 2019 (transition extra tropicale)' )\n",
    "    print ('16 -- Alex - Octobre 2020' )\n",
    "    print ('17 -- Ciaran - Octobre-novembre 2023' )\n",
    "\n",
    "print_menu()\n",
    "\n",
    "option = int(input('Enter number of the desired storm : ')) \n",
    "if option == 1:\n",
    "    storm='Nov1982'\n",
    "elif option == 2:\n",
    "    storm='Oct1987'\n",
    "elif option == 3:\n",
    "    storm='Herta'\n",
    "elif option == 4:\n",
    "    storm='Viviane'\n",
    "elif option == 5:\n",
    "    storm='Braer'\n",
    "elif option == 6:\n",
    "    storm='Lothar'\n",
    "elif option == 7:\n",
    "    storm='Martin'\n",
    "elif option == 8:\n",
    "    storm='Klaus'\n",
    "elif option == 9:\n",
    "    storm='Xynthia'\n",
    "elif option == 10:\n",
    "    storm='Joachim'\n",
    "elif option == 11:\n",
    "    storm='Zeus'\n",
    "elif option == 12:\n",
    "    storm='Ophelia'\n",
    "elif option == 13:\n",
    "    storm='Eleanor'\n",
    "elif option == 14:\n",
    "    storm='Zorbas'\n",
    "elif option == 15:\n",
    "    storm='Lorenzo'\n",
    "elif option == 16:\n",
    "    storm='Alex'\n",
    "elif option == 17:\n",
    "    storm='Ciaran'\n",
    "\n",
    "else:\n",
    "    print('Invalid option. Please enter a number between 1 and 17.')\n",
    "    \n",
    "if not os.path.exists('./anim/'+storm):\n",
    "    os.mkdir('./anim/'+storm)\n",
    "\n",
    "if not os.path.exists('./figs/'+storm):\n",
    "    os.mkdir('./figs/'+storm)\n",
    "    \n",
    "dir_anim ='./anim/'+storm+'/'\n",
    "dir_data ='./data/'+storm+'/'\n",
    "\n",
    "if os.path.exists(dir_data+\"msl.nc\") or os.path.exists(dir_data+\"msl1.nc\"):\n",
    "    print('All good : MSLP file is present in the folder data/'+storm)\n",
    "else:\n",
    "    print('Warning : MSLP file is not present in the folder data/'+storm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if storm=='Nov1982':\n",
    "    date1='1982-11-06T03'\n",
    "    date2='1982-11-08T12'                                 \n",
    "if storm=='Oct1987':\n",
    "    date1='1987-10-15T09'\n",
    "    date2='1987-10-16T23'                               \n",
    "if storm=='Herta':\n",
    "    date1='1990-02-02T09'\n",
    "    date2='1990-02-04T05'                                 \n",
    "if storm=='Viviane':\n",
    "    date1='1990-02-26T00'\n",
    "    date2='1990-02-28T00'\n",
    "if storm=='Braer':\n",
    "    date1='1993-01-08T22'\n",
    "    date2='1993-01-13T23'\n",
    "if storm=='Lothar':\n",
    "    date1='1999-12-25T00'\n",
    "    date2='1999-12-26T15'                                 \n",
    "if storm=='Martin':\n",
    "    date1='1999-12-26T12'\n",
    "    date2='1999-12-28T04'                                 \n",
    "if storm=='Klaus':\n",
    "    date1='2009-01-23T06'\n",
    "    date2='2009-01-24T15'                                 \n",
    "if storm=='Xynthia':\n",
    "    date1='2010-02-26T21'\n",
    "    date2='2010-02-28T21'                                 \n",
    "if storm=='Joachim':\n",
    "    date1='2011-12-15T03'\n",
    "    date2='2011-12-17T23'\n",
    "if storm=='Zeus':\n",
    "    date1='2017-03-06T04'\n",
    "    date2='2017-03-07T23' \n",
    "if storm=='Ophelia':\n",
    "    date1='2017-10-14T00'\n",
    "    date2='2017-10-17T21'                                \n",
    "if storm=='Eleanor':\n",
    "    date1='2018-01-02T20'\n",
    "    date2='2018-01-04T10'\n",
    "if storm=='Zorbas':\n",
    "    date1='2018-09-27T05'\n",
    "    date2='2018-09-30T23'\n",
    "if storm=='Lorenzo':\n",
    "    date1='2019-10-01T00'\n",
    "    date2='2019-10-04T23'  \n",
    "if storm=='Alex':\n",
    "    date1='2020-10-01T14'\n",
    "    date2='2020-10-03T06'\n",
    "if storm=='Ciaran':\n",
    "    date1='2023-10-30T18'\n",
    "    date2='2023-11-03T22'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ouverture des données de Pmer pour la tempête choisie pour la période retenue et sur un sous-domaine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latS=30\n",
    "latN=70\n",
    "lonW=-60\n",
    "lonE=30\n",
    "\n",
    "if storm=='Braer':\n",
    "    latS=40\n",
    "    latN=80\n",
    "    lonW=-80\n",
    "    lonE=20\n",
    "if storm=='Ciaran':\n",
    "    latS=30\n",
    "    latN=70\n",
    "    lonW=-70\n",
    "    lonE=30\n",
    "if storm=='Lorenzo':\n",
    "    latS=25\n",
    "    latN=60\n",
    "    lonW=-60\n",
    "    lonE=20\n",
    "if storm=='Zorbas':\n",
    "    latS=30\n",
    "    latN=45\n",
    "    lonW=5\n",
    "    lonE=35\n",
    "    \n",
    "f1    = xr.open_mfdataset(dir_data+\"msl*.nc\").sel(time=slice(date1,date2)).sel(latitude=slice(latN,latS))\n",
    "print(f1)\n",
    "\n",
    "mslp0 = f1['msl']/100\n",
    "lat  = mslp0.latitude.values\n",
    "time  = mslp0.time.values\n",
    "\n",
    "mslp = lonflip(mslp0)\n",
    "mslp=mslp.sel(longitude=slice(lonW,lonE))\n",
    "\n",
    "lon  = mslp.longitude.values\n",
    "\n",
    "print(mslp)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Pour tous les pas de temps, on détecte les minimas présents sur le domaine et on sauvegarde dans un fichier texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "for i in tqdm(range(len(time))):\n",
    "    date=str(time[i])[0:13]   \n",
    "    print_maxmin_points(mslp[i,:,:], 'min', 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file_era = './txt/era5_minimums_'+date1+'_'+date2+'.txt'\n",
    "with open(file_era, 'w') as f:\n",
    "    f.write(cap.stdout)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fonction de tracking automatique à partir de la date de départ (utilisation de shapely)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer=3\n",
    "if storm=='Martin':\n",
    "    buffer=4\n",
    "if storm=='Braer':\n",
    "    buffer=4\n",
    "    \n",
    "def tracking(file): \n",
    "    df = pd.read_csv(file,sep=\" \",header=None)\n",
    "    liste_date =  np.unique(df[0].values)\n",
    "    ds = df.to_xarray()\n",
    "    \n",
    "    # We will track lows that are present at initial time\n",
    "    original_position = ds.sel(index= ds[0] == liste_date[0])\n",
    "    \n",
    "    # Build individual tracking for each detected low\n",
    "    traj = []\n",
    "    for ind in original_position.index.values: # Boucle sur les depressions à t=0\n",
    "        position = Point(original_position.sel(index=ind)[1],original_position.sel(index=ind)[2])\n",
    "        dep_traj = []\n",
    "        dep_traj.append((\n",
    "            original_position.sel(index=ind)[1].values,\n",
    "            original_position.sel(index=ind)[2].values,\n",
    "            original_position.sel(index=ind)[0].values,\n",
    "            original_position.sel(index=ind)[3].values, \n",
    "            ))\n",
    "        for date in liste_date[1:]: # Loop for all timesteps\n",
    "            temp = ds.sel(index= ds[0] == date)\n",
    "            l_area = []\n",
    "            for other_idx in temp.index.values: \n",
    "                oth_pos = Point(temp.sel(index=other_idx)[1],temp.sel(index=other_idx)[2])\n",
    "                l_area.append(position.buffer(buffer).intersection(oth_pos.buffer(buffer)).area) \n",
    "                # Finding intersection between two circles of 1°. \n",
    "            if np.max(l_area)>0.001: # Compare areas\n",
    "                elt = np.argmax(l_area)\n",
    "                n_position=Point(temp.isel(index=elt)[1],temp.isel(index=elt)[2])\n",
    "                dep_traj.append([\n",
    "                    temp.isel(index=elt)[1].values,\n",
    "                    temp.isel(index=elt)[2].values,\n",
    "                    temp.isel(index=elt)[0].values,\n",
    "                    temp.isel(index=elt)[3].values] )\n",
    "                position = n_position\n",
    "            else: \n",
    "                break\n",
    "        traj.append(dep_traj)\n",
    "    return traj"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Construction des trajectoires à partir de tous les minimums détectés du fichier texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tracking_era = tracking(file_era)\n",
    "print(\"Number of tracked lows starting at \"+date1+\": \", len(tracking_era))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(tracking_era[0][0])\n",
    "print(tracking_era[1][0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fonction de construction des listes lon/lat/time/pres pour une trajectoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_list(track): \n",
    "    list_lat = []\n",
    "    list_lon = []\n",
    "    list_time = []\n",
    "    list_pres = []\n",
    "    for i in range(len(track)):\n",
    "        list_lon.append(track[i][0])\n",
    "        list_lat.append(track[i][1])\n",
    "        list_time.append(track[i][2])\n",
    "        list_pres.append(track[i][3])\n",
    "    return list_lon, list_lat, list_time, list_pres"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Sauvegarde de toutes les trajectoires dans un fichier texte (signe # avant chaque nouvelle trajectoire)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file_storms = './txt/era5_tracks_'+date1+'.txt'\n",
    "file=open(file_storms, \"w+\")\n",
    "\n",
    "for i in range(len(tracking_era)):\n",
    "    file.write(\"#\")\n",
    "    #file.write(\"\\n\")\n",
    "\n",
    "    liste_lon, liste_lat, liste_time, liste_pres = get_list(tracking_era[i])\n",
    "    list_time = [str(x) for x in liste_time]\n",
    "    \n",
    "    for j in range(len(tracking_era[i])):\n",
    "        file.write(str(liste_time[j]))\n",
    "        file.write(' ')\n",
    "        file.write(str(liste_lon[j]))\n",
    "        file.write(' ')\n",
    "        file.write(str(liste_lat[j]))\n",
    "        file.write(' ')\n",
    "        file.write(str(liste_pres[j]))\n",
    "        file.write(\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé des trajectoires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mslp_levels = np.arange(900,1072,2)\n",
    "projection=ccrs.NearsidePerspective(central_longitude=(lonW+lonE)/2, central_latitude=(latS+latN)/2)\n",
    "if storm=='Zorbas':\n",
    "    projection=ccrs.PlateCarree()\n",
    "\n",
    "bounds = [(lonW, lonE, latS, latN)]\n",
    "\n",
    "fig = plt.figure(figsize=(15., 10.))\n",
    "ax = fig.add_subplot(111, projection=projection)\n",
    "ax.set_title('Tracks of all systems detected at '+date1,loc='center',fontsize=14)\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon, lat)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "LAND = cfeature.NaturalEarthFeature('physical', 'land', '10m',edgecolor='face',facecolor=cfeature.COLORS['land'],linewidth=.1)\n",
    "ax.add_feature(LAND)\n",
    "OCEAN = cfeature.NaturalEarthFeature('physical', 'ocean', '10m',edgecolor='face',facecolor=cfeature.COLORS['water'],linewidth=.1)\n",
    "ax.add_feature(OCEAN)\n",
    "ax.gridlines(draw_labels=False, color='gray', alpha=0.8, linestyle='-')\n",
    "c = ax.contour(lon, lat, mslp[0,:,:], levels=mslp_levels, colors=\"grey\", linewidths=1, transform=ccrs.PlateCarree())\n",
    "ax.clabel(c,fmt='%4.1i',fontsize=10)\n",
    "\n",
    "for ind in range(len(tracking_era)):\n",
    "    liste_lon, liste_lat, liste_time, liste_pres = get_list(tracking_era[ind])\n",
    "    ax.plot(liste_lon,liste_lat, label=ind, transform=ccrs.PlateCarree())\n",
    "    ax.scatter(liste_lon[0],liste_lat[0], color='green', transform=ccrs.PlateCarree())\n",
    "    ax.scatter(liste_lon[-1],liste_lat[-1], color='red', transform=ccrs.PlateCarree())\n",
    "    ax.text(liste_lon[0], liste_lat[0], liste_pres[0],verticalalignment='top', horizontalalignment='center',\n",
    "            transform=ccrs.PlateCarree())\n",
    "    ax.text(liste_lon[-1], liste_lat[-1], liste_pres[-1],verticalalignment='top', horizontalalignment='center',\n",
    "            transform=ccrs.PlateCarree())\n",
    "plt.legend(loc='right')\n",
    "plt.show()\n",
    "\n",
    "figname='./figs/'+storm+'/tracks_'+date1\n",
    "fig.savefig(figname+'.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé des trajectoires d'une durée de plus de 24h."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15., 10.))\n",
    "ax = fig.add_subplot(111, projection=projection)\n",
    "ax.set_title('Tracks of all systems detected at '+date1+' and lasting at least 24h',loc='center',fontsize=14)\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon, lat)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "LAND = cfeature.NaturalEarthFeature('physical', 'land', '10m',edgecolor='face',facecolor=cfeature.COLORS['land'],linewidth=.1)\n",
    "ax.add_feature(LAND)\n",
    "OCEAN = cfeature.NaturalEarthFeature('physical', 'ocean', '10m',edgecolor='face',facecolor=cfeature.COLORS['water'],linewidth=.1)\n",
    "ax.add_feature(OCEAN)\n",
    "ax.gridlines(draw_labels=False, color='gray', alpha=0.8, linestyle='-')\n",
    "c = ax.contour(lon, lat, mslp[0,:,:], levels=mslp_levels, colors=\"grey\", linewidths=1, transform=ccrs.PlateCarree())\n",
    "ax.clabel(c,fmt='%4.1i',fontsize=10)\n",
    "\n",
    "for ind in range(len(tracking_era)):\n",
    "    liste_lon, liste_lat, liste_time, liste_pres = get_list(tracking_era[ind])\n",
    "    if len(liste_lon) >24: \n",
    "        ax.plot(liste_lon,liste_lat, label=ind, transform=ccrs.PlateCarree())\n",
    "        ax.scatter(liste_lon[0],liste_lat[0], color='green', transform=ccrs.PlateCarree())\n",
    "        ax.scatter(liste_lon[-1],liste_lat[-1], color='red', transform=ccrs.PlateCarree())\n",
    "        ax.text(liste_lon[0], liste_lat[0], liste_pres[0],verticalalignment='top', horizontalalignment='center',\n",
    "                transform=ccrs.PlateCarree())\n",
    "        ax.text(liste_lon[-1], liste_lat[-1], liste_pres[-1],verticalalignment='top', horizontalalignment='center',\n",
    "                transform=ccrs.PlateCarree())\n",
    "plt.legend(loc='right')\n",
    "plt.show()\n",
    "\n",
    "figname='./figs/'+storm+'/tracks24h_'+date1\n",
    "fig.savefig(figname+'.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Selection de la tempête parmi les trajectoires calculées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ind_era = int(input(\"Enter index of storm \"+storm+\" : \"))\n",
    "print('Number of points for the desired low : '+str(len(tracking_era[ind_era])))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Sauvegarde de la trajectoire retenue dans un fichier texte storm.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Méthode 1 : A partir du fichier texte des trajectoires (grâce au séparateur #)\n",
    "\n",
    "with open(file_storms, 'r', encoding='utf-8') as file:\n",
    "    contents = file.read()\n",
    "    character = '#'\n",
    "    result = contents.split(character, len(tracking_era))\n",
    "print(result[ind_era+1])\n",
    "\n",
    "file_storm = './txt/'+storm+'.txt'\n",
    "with open(file_storm, 'w') as f:\n",
    "    f.write(result[ind_era+1])\n",
    "    \n",
    "### Méthode 2 : avec la fonction get_list()\n",
    "\n",
    "#liste_lon, liste_lat, liste_time, liste_pres = get_list(tracking_era[ind_era])\n",
    "\n",
    "#file_storm = './txt/'+storm+'.txt'\n",
    "#file=open(file_storm, \"w+\")\n",
    "#for i in range(len(tracking_era[ind_era])):\n",
    "#    file.write(str(liste_time[i]))\n",
    "#    file.write(' ')\n",
    "#    file.write(str(liste_lon[i]))\n",
    "#    file.write(' ')\n",
    "#    file.write(str(liste_lat[i]))\n",
    "#    file.write(' ')\n",
    "#    file.write(str(liste_pres[i]))\n",
    "#    file.write(\"\\n\")\n",
    "#file.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Construction de l'animation du tracking de la tempête retenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "liste_lon, liste_lat, liste_time, liste_pres = get_list(tracking_era[ind_era])\n",
    "list_time = [str(x) for x in liste_time]\n",
    "\n",
    "for i in tqdm(range(len(tracking_era[ind_era]))):\n",
    "    #print(str(tracking_era[ind_era][i][2])[0:13])\n",
    "    fig = plt.figure(figsize=(15., 10.))\n",
    "\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=projection)\n",
    "    ax.set_title('Storm '+storm+' - MSLP and tracking : '+list_time[0]+' to ' +list_time[-1],loc='left',fontsize=14)\n",
    "    ax.set_title(str(time[i])[0:13],loc='right',fontsize=14)\n",
    "    ax.coastlines(\"10m\", color='grey', zorder=3)\n",
    "    ax.gridlines(draw_labels=False, color='gray', alpha=0.8, linestyle='-')\n",
    "    ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "    boundary_path = make_boundary_path(lon, lat)\n",
    "    ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())  \n",
    "    \n",
    "    c1 = ax.contour(lon, lat, mslp[i,:,:], levels=mslp_levels, colors=\"black\", linewidths=1, transform=ccrs.PlateCarree())\n",
    "    ax.clabel(c1,fmt='%4.1i',fontsize=10)\n",
    "    plot_maxmin_points(mslp[i,:,:], 'min', 25,\n",
    "                       symbol='L', color='b', transform=ccrs.PlateCarree()) \n",
    "\n",
    "    ax.plot(liste_lon[0:i+1],liste_lat[0:i+1], c='red', marker='+', transform=ccrs.PlateCarree())\n",
    "    \n",
    "    figname='./anim/'+storm+'/MSL_tracking2_'+list_time[i]\n",
    "    fig.savefig(figname+'.png',bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gif_filepath = './anim/'+storm+'/MSL_tracking2.gif'\n",
    "make_animation(gif_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
